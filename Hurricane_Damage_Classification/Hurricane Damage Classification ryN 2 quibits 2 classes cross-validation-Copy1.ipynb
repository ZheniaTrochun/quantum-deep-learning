{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from torch) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: qiskit in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: qiskit-ignis==0.5.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit) (0.5.1)\n",
      "Requirement already satisfied: qiskit-aqua==0.8.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit) (0.8.1)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.11.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit) (0.11.1)\n",
      "Requirement already satisfied: qiskit-aer==0.7.2 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit) (0.7.2)\n",
      "Requirement already satisfied: qiskit-terra==0.16.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit) (0.16.1)\n",
      "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ignis==0.5.1->qiskit) (0.23.2)\n",
      "Requirement already satisfied: scipy!=0.19.1,>=0.19 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ignis==0.5.1->qiskit) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ignis==0.5.1->qiskit) (50.3.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ignis==0.5.1->qiskit) (1.19.2)\n",
      "Requirement already satisfied: retworkx>=0.5.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (0.7.2)\n",
      "Requirement already satisfied: dlx in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (1.0.4)\n",
      "Requirement already satisfied: docplex in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (2.19.202)\n",
      "Requirement already satisfied: quandl in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (3.6.0)\n",
      "Requirement already satisfied: yfinance in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (0.1.55)\n",
      "Requirement already satisfied: fastdtw in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (0.3.4)\n",
      "Requirement already satisfied: sympy>=1.3 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (1.7.1)\n",
      "Requirement already satisfied: pandas in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (1.1.3)\n",
      "Requirement already satisfied: h5py in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (2.10.0)\n",
      "Requirement already satisfied: psutil>=5 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aqua==0.8.1->qiskit) (5.8.0)\n",
      "Requirement already satisfied: requests-ntlm>=1.1.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.1.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (2.8.1)\n",
      "Requirement already satisfied: requests>=2.19 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (2.24.0)\n",
      "Requirement already satisfied: nest-asyncio!=1.1.0,>=1.0.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.4.0)\n",
      "Requirement already satisfied: websockets>=8 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (8.1)\n",
      "Requirement already satisfied: cython>=0.27.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aer==0.7.2->qiskit) (0.29.21)\n",
      "Requirement already satisfied: pybind11>=2.4 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-aer==0.7.2->qiskit) (2.6.1)\n",
      "Requirement already satisfied: ply>=3.10 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-terra==0.16.1->qiskit) (3.11)\n",
      "Requirement already satisfied: dill>=0.3 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-terra==0.16.1->qiskit) (0.3.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-terra==0.16.1->qiskit) (3.2.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.10 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-terra==0.16.1->qiskit) (2.14.5)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-terra==0.16.1->qiskit) (2.5)\n",
      "Requirement already satisfied: python-constraint>=1.4 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from qiskit-terra==0.16.1->qiskit) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from scikit-learn>=0.17->qiskit-ignis==0.5.1->qiskit) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from scikit-learn>=0.17->qiskit-ignis==0.5.1->qiskit) (0.17.0)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from docplex->qiskit-aqua==0.8.1->qiskit) (1.15.0)\n",
      "Requirement already satisfied: more-itertools in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from quandl->qiskit-aqua==0.8.1->qiskit) (8.6.0)\n",
      "Requirement already satisfied: inflection>=0.3.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from quandl->qiskit-aqua==0.8.1->qiskit) (0.5.1)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from yfinance->qiskit-aqua==0.8.1->qiskit) (0.0.9)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from yfinance->qiskit-aqua==0.8.1->qiskit) (4.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from sympy>=1.3->qiskit-aqua==0.8.1->qiskit) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from pandas->qiskit-aqua==0.8.1->qiskit) (2020.1)\n",
      "Requirement already satisfied: cryptography>=1.3 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (3.3.1)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (1.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (2020.6.20)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from jsonschema>=2.6->qiskit-terra==0.16.1->qiskit) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from jsonschema>=2.6->qiskit-terra==0.16.1->qiskit) (20.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from networkx>=2.2->qiskit-terra==0.16.1->qiskit) (4.4.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi>=1.12 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (1.14.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (2.20)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pylatexenc in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (2.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torchvision in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (0.8.2)\n",
      "Requirement already satisfied: torch==1.7.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from torchvision) (1.7.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from torchvision) (7.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from torch==1.7.1->torchvision) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (1.19.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (4.56.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement itertools (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for itertools\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.2.8/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install qiskit\n",
    "!{sys.executable} -m pip install pylatexenc\n",
    "!{sys.executable} -m pip install torchvision\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install tqdm\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 1\n",
    "NUM_SHOTS = 5000\n",
    "SHIFT = np.pi/4\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "BATCH_SIZE=25\n",
    "\n",
    "SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n"
     ]
    }
   ],
   "source": [
    "# create list of all possible outputs of quantum circuit (2**NUM_QUBITS possible)\n",
    "import itertools\n",
    "\n",
    "def create_QC_OUTPUTS():\n",
    "    measurements = list(itertools.product([0, 1], repeat=NUM_QUBITS))\n",
    "    return [''.join([str(bit) for bit in measurement]) for measurement in measurements]\n",
    "\n",
    "QC_OUTPUTS = create_QC_OUTPUTS()\n",
    "print(QC_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct QuantumCircuit QFT Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.thetas = { k: Parameter('Theta'+str(k)) for k in range(self.n_qubits) }\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        \n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        for k in range(n_qubits):\n",
    "            self.circuit.ry(self.thetas[k], k)\n",
    "            \n",
    "        self.circuit.measure_all()\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "    def N_qubits_expectation_Z(self, counts, shots, n_qubits):\n",
    "        expects = np.zeros(len(QC_OUTPUTS))\n",
    "        for k in range(len(QC_OUTPUTS)):\n",
    "            key = QC_OUTPUTS[k]\n",
    "            perc = counts.get(key, 0) / shots\n",
    "            expects[k] = perc\n",
    "        return expects\n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "        \n",
    "        job_sim = execute(self.circuit, \n",
    "                          self.backend, \n",
    "                          shots = self.shots, \n",
    "                          parameter_binds = [{ self.thetas[k]: params[k].item() for k in range(self.n_qubits) }])\n",
    "        \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        \n",
    "        return self.N_qubits_expectation_Z(counts, self.shots, self.n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4]: [0.1488 0.8512]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 417.879x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QuantumCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print(f'Expected value for rotation [pi/4]: {circuit.run(torch.Tensor([np.pi/4] * len(QC_OUTPUTS)))}')\n",
    "circuit.circuit.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        if not hasattr(ctx, 'QuantumCircuit'):\n",
    "            ctx.QuantumCircuit = QuantumCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "        \n",
    "        exp_value = ctx.QuantumCircuit.run(input)    \n",
    "        \n",
    "        result = torch.Tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, input)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        forward_tensor,i = ctx.saved_tensors\n",
    "        \n",
    "        input_numbers = i\n",
    "        gradients = torch.Tensor()\n",
    "        \n",
    "        for k in range(NUM_QUBITS):\n",
    "            shift_right = input_numbers.detach().clone()\n",
    "            shift_right[k] = shift_right[k] + SHIFT\n",
    "            \n",
    "            shift_left = input_numbers.detach().clone()\n",
    "            shift_left[k] = shift_left[k] - SHIFT\n",
    "            \n",
    "            expectation_right = ctx.QuantumCircuit.run(shift_right)\n",
    "            expectation_left = ctx.QuantumCircuit.run(shift_left)\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradient = gradient / torch.norm(gradient)\n",
    "            \n",
    "            gradients = torch.cat((gradients, gradient.float()))\n",
    "            \n",
    "        result = torch.Tensor(gradients)\n",
    "        \n",
    "        return (result.float() * grad_output.float()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLayer(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HybridLayer, self).__init__()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return TorchCircuit.apply(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([0.7854], requires_grad=True)\n",
      "y1 after quantum layer: tensor([[0.1482, 0.8518]], grad_fn=<TorchCircuitBackward>)\n",
      "x.grad = tensor([-0.3153])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.pi/4] * NUM_QUBITS, requires_grad=True)\n",
    "qc = TorchCircuit.apply\n",
    "\n",
    "y1 = qc(x)\n",
    "print(f'y1 after quantum layer: {y1}')\n",
    "y1 = nn.Linear(2**NUM_QUBITS, 1)(y1.float())\n",
    "\n",
    "y1.backward()\n",
    "print(f'x.grad = {x.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:03, 24.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-0.7854], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-0.8854], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-0.9854], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.0853], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.1851], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.2850], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:00<00:03, 26.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.3847], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.4844], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5840], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6515], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6936], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.7153], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:00<00:03, 25.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.7202], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.7112], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6905], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6600], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6210], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:00<00:03, 25.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5748], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5224], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.4875], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.4678], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.4614], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.4668], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:01<00:02, 24.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.4825], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5073], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5401], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5801], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6263], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:01<00:02, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.6572], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6745], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6795], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6737], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6582], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6340], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:01<00:02, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.6020], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5631], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5384], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5263], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5257], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5352], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:01<00:02, 26.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5538], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5807], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5947], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5973], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5895], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5725], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:01<00:01, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5472], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5344], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5330], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5417], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5596], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5857], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:02<00:01, 27.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5991], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.6012], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5931], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5758], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5503], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5373], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:02<00:01, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5356], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5440], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5616], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5675], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5827], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5865], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [00:02<00:01, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5798], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5639], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5595], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5656], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5810], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5849], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:02<00:00, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5785], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5627], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5584], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5646], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5801], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5841], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:03<00:00, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([-1.5777], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([-1.5620], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [00:03<00:00, 27.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [00:03<00:00, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:03<00:00, 27.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n",
      "inside circuit\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1495a18b0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    \n",
    "    val = sum([(i + 1) * expval[i] for i in range(2**NUM_QUBITS)]) / 2**NUM_QUBITS\n",
    "    \n",
    "    return torch.abs(target - val) ** 2, expval\n",
    "\n",
    "\n",
    "x = torch.tensor([-np.pi/4] * NUM_QUBITS, requires_grad=True)\n",
    "opt = optim.Adam([x], lr = 0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "    \n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./data/hurricane_damage_dataset/test/\"\n",
    "TEST_DATA_PATH = \"./data/hurricane_damage_dataset/validation_another/\"\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "\n",
    "train_samples = 900\n",
    "test_samples = 100\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "# train_idx = np.append(np.where(train_data.targets == 0)[0][:train_samples], \n",
    "#                 np.where(train_data.targets == 1)[0][:train_samples])\n",
    "\n",
    "X_train = torch.utils.data.Subset(train_data, np.random.choice(len(train_data), train_samples, replace=False))\n",
    "\n",
    "\n",
    "# train_data.data = train_data.data[train_idx]\n",
    "# train_data.targets = train_data.targets[train_idx]\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n",
    "# test_idx = np.append(np.where(test_data.targets == 0)[0][:test_samples], \n",
    "#                 np.where(test_data.targets == 1)[0][:test_samples])\n",
    "\n",
    "# test_data.data = test_data.data[test_idx]\n",
    "# test_data.targets = test_data.targets[test_idx]\n",
    "\n",
    "X_test = torch.utils.data.Subset(test_data, np.random.choice(len(test_data), test_samples, replace=False))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=100, shuffle=True, pin_memory=True)\n",
    "test_loader  = torch.utils.data.DataLoader(X_test, batch_size=100, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tforms = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor(),\n",
    "#                              transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
    "# train_tfroms = transforms.Compose([transforms.Resize((128, 128)),transforms.ColorJitter(),\n",
    "#                                    transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "#                                    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
    "\n",
    "# # Load train image data\n",
    "# traindataFromFolders = datasets.ImageFolder(root = './data/hurricane_damage_dataset/train_another/', transform = train_tfroms)\n",
    "# train_loader = DataLoader(traindataFromFolders, batch_size = 100,  shuffle = True)\n",
    "# x_train, y_train = iter(train_loader).next()\n",
    "\n",
    "# # Load validation image data\n",
    "# valdataFromFolders = datasets.ImageFolder(root = './data/hurricane_damage_dataset/validation_another/', transform = tforms)\n",
    "# val_loader = DataLoader(valdataFromFolders,batch_size = 100, shuffle = True)\n",
    "# x_val, y_val = iter(val_loader).next()\n",
    "\n",
    "# # Load test image data\n",
    "# testdataFromFolders = datasets.ImageFolder(root = './data/hurricane_damage_dataset/test_another/', transform = train_tfroms)\n",
    "# test_loader = DataLoader(testdataFromFolders,batch_size = 20, shuffle = False)\n",
    "# x_test, y_test = iter(test_loader).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sample_shape = (8, 6)\n",
    "# count = 0\n",
    "# fig, axes = plt.subplots(nrows=n_sample_shape[0], ncols=n_sample_shape[1], figsize=(10, 2*n_sample_shape[0]))\n",
    "\n",
    "# # classes_map = {\n",
    "# #     0: 'T-shirt/top',\n",
    "# #     1: 'Trouser',\n",
    "# #     2: 'Pullover',\n",
    "# #     3: 'Dress',\n",
    "# #     4: 'Coat',\n",
    "# #     5: 'Sandal',\n",
    "# #     6: 'Shirt',\n",
    "# #     7: 'Sneaker',\n",
    "# #     8: 'Bag',\n",
    "# #     9: 'Ankle boot'\n",
    "# # }\n",
    "\n",
    "# # network.eval()\n",
    "# # with torch.no_grad():\n",
    "# for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#     if count == n_sample_shape[0]*n_sample_shape[1]:\n",
    "#         break\n",
    "\n",
    "# #     prediction = network.predict(data).item()\n",
    "\n",
    "#     prepared_img = data[0].numpy().squeeze()\n",
    "\n",
    "#     axes[count // n_sample_shape[1]][count % n_sample_shape[1]].imshow(data[0].permute(1, 2, 0))\n",
    "\n",
    "#     axes[count // n_sample_shape[1]][count % n_sample_shape[1]].set_xticks([])\n",
    "#     axes[count // n_sample_shape[1]][count % n_sample_shape[1]].set_yticks([])\n",
    "#     axes[count // n_sample_shape[1]][count % n_sample_shape[1]].set_title(target[0].item())\n",
    "\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_samples = 1000\n",
    "\n",
    "# X_train = datasets.FashionMNIST(root='./data', \n",
    "#                                 train=True,\n",
    "#                                 download=True,\n",
    "#                                 transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "#                 np.where(X_train.targets == 1)[0][:n_samples])\n",
    "# # idx = np.append(idx, \n",
    "# #                 np.where(X_train.targets == 2)[0][:n_samples])\n",
    "# # idx = np.append(idx, \n",
    "# #                 np.where(X_train.targets == 3)[0][:n_samples])\n",
    "\n",
    "# X_train.data = X_train.data[idx]\n",
    "# X_train.targets = X_train.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 50\n",
    "\n",
    "# X_test = datasets.FashionMNIST(root='./data', \n",
    "#                                train=False,\n",
    "#                                download=True,\n",
    "#                                transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "#                 np.where(X_test.targets == 1)[0][:n_samples])\n",
    "# # idx = np.append(idx, \n",
    "# #                 np.where(X_test.targets == 2)[0][:n_samples])\n",
    "# # idx = np.append(idx, \n",
    "# #                 np.where(X_test.targets == 3)[0][:n_samples])\n",
    "\n",
    "# X_test.data = X_test.data[idx]\n",
    "# X_test.targets = X_test.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv3 = nn.Conv2d(20, 20, kernel_size=5)\n",
    "#         self.conv4 = nn.Conv2d(20, 20, kernel_size=5)\n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.fc1 = nn.Linear(320, 50)\n",
    "#         self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "#         self.qc = TorchCircuit.apply\n",
    "#         self.qcsim = nn.Linear(NUM_QUBITS, 1)\n",
    "\n",
    "        DROPOUT = 0.5\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convnorm1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=6, stride=1, padding=1)\n",
    "        self.convnorm2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size = 6, stride = 1, padding = 1)\n",
    "        self.convnorm3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.AvgPool2d((2, 2))\n",
    "\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.linear1 = nn.Linear(64 * 13 * 13, 16)\n",
    "        self.linear1_bn = nn.BatchNorm1d(16)\n",
    "        self.linear2 = nn.Linear(16, NUM_QUBITS)\n",
    "        self.linear2_bn = nn.BatchNorm1d(NUM_QUBITS)\n",
    "#         self.linear2 = nn.Linear(16, 2)\n",
    "#         self.linear2_bn = nn.BatchNorm1d(2)\n",
    "#         self.qc = TorchCircuit.apply\n",
    "        self.qc = HybridLayer()\n",
    "        self.sigmoid = torch.sigmoid\n",
    "        self.relu = torch.relu\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv4(x)), 2))\n",
    "#         x = x.view(-1, 320)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc2(x)\n",
    "#         x = np.pi*torch.tanh(x)\n",
    "        \n",
    "#         MODE = 'QC'\n",
    "        \n",
    "#         if MODE == 'QC':\n",
    "#             x = self.qc(x[0])\n",
    "#         else:\n",
    "#             x = self.qcsim(x)\n",
    "            \n",
    "#         x = torch.sigmoid(x)\n",
    "#         x = torch.cat((x, 1-x), -1)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         x = self.pool1(self.relu(self.conv1(x)))\n",
    "#         x = self.pool2(self.relu(self.conv2(x)))\n",
    "#         x = self.pool3(self.relu(self.conv3(x)))\n",
    "#         x = x.view(-1, 64 * 13 * 13)\n",
    "#         x = self.dropout(self.relu(self.linear1(x)))\n",
    "#         x = self.dropout(self.relu(self.linear2(x)))\n",
    "\n",
    "\n",
    "        x = self.pool1(self.convnorm1(self.relu(self.conv1(x))))\n",
    "        x = self.pool2(self.convnorm2(self.relu(self.conv2(x))))\n",
    "        x = self.pool3(self.convnorm3(self.relu(self.conv3(x))))\n",
    "        x = x.view(-1, 64 * 13 * 13)\n",
    "        x = self.dropout(self.linear1_bn(self.relu(self.linear1(x))))\n",
    "        x = self.dropout(self.linear2_bn(self.relu(self.linear2(x))))\n",
    "        \n",
    "#         print(x)\n",
    "\n",
    "        x = torch.cat((x, torch.zeros(25, 1)), dim=-1)\n",
    "#         x.apply_(lambda x: x + 1)\n",
    "#         print(x)\n",
    "    \n",
    "        y = torch.zeros_like(x, device=x.device)\n",
    "        \n",
    "        for i in range(0, BATCH_SIZE):\n",
    "            qc_res = self.qc(x[i])\n",
    "#             print(qc_res)\n",
    "#             cat_res = torch.cat((qc_res, 1-qc_res), -1)\n",
    "#             print(cat_res)\n",
    "#             arg_max_res = torch.argmax(cat_res[0])\n",
    "#             print(arg_max_res)\n",
    "#             print(torch.argmax(qc_res[0]).item())\n",
    "\n",
    "#             x[i] = torch.cat((qc_res, 1-qc_res), -1) # TODO: maybe more correct ????\n",
    "#             x[i] = torch.argmax(qc_res[0]) # TODO: maybe more correct ????\n",
    "\n",
    "            y[i] = qc_res[0]\n",
    "            \n",
    "#         x = self.qc(x[0])\n",
    "        x = y\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "#         x = torch.cat((x, 1-x), -1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \n",
    "#         return self.forward(x)\n",
    "        pred = self.forward(x)\n",
    "        ans = torch.argmax(pred[0]).item()\n",
    "        \n",
    "        return torch.tensor(ans)\n",
    "    \n",
    "# network = Net()\n",
    "# optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "LR = 0.01\n",
    "\n",
    "network = Net()\n",
    "# optimizer = torch.optim.SGD(network.parameters(), lr = LR, momentum = 0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Pytoch\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Timing utility\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizationsos\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def acc(x, y, model, return_labels = False):\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        pred_labels = np.argmax(logits.cpu().numpy(), axis = 1)\n",
    "    if return_labels:\n",
    "        return pred_labels\n",
    "    else:\n",
    "        return 100*accuracy_score(y.cpu().numpy(), pred_labels)\n",
    "\n",
    "\n",
    "def train_network(network, optimizer, train_loader, val_loader):\n",
    "    epochs = 20\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    loaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader\n",
    "    }\n",
    "    \n",
    "    loss_results = {\n",
    "        'train': [],\n",
    "        'val': []\n",
    "    }\n",
    "\n",
    "    acc_results = {\n",
    "        'train': [],\n",
    "        'val': []\n",
    "    }\n",
    "\n",
    "    loaders = {\n",
    "        'train': train_loader,\n",
    "        'val': test_loader\n",
    "    }\n",
    "\n",
    "    x_train, y_train = iter(train_loader).next()\n",
    "    x_val, y_val = iter(val_loader).next()\n",
    "        \n",
    "    history_li = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = {\n",
    "            'train': [],\n",
    "            'val': []\n",
    "        }\n",
    "\n",
    "        total_acc = {\n",
    "            'train': [],\n",
    "            'val': []\n",
    "        }\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        network.train()\n",
    "        start = timer()\n",
    "\n",
    "        loss_train = 0\n",
    "        network.train()\n",
    "        \n",
    "        for batch in range(len(x_train)//BATCH_SIZE):\n",
    "\n",
    "            inds = slice(batch*BATCH_SIZE, (batch+1)*BATCH_SIZE)\n",
    "            optimizer.zero_grad()\n",
    "            logits = network(x_train[inds])\n",
    "            print(logits)\n",
    "            print(y_train[inds])\n",
    "            loss = criterion(logits, y_train[inds])\n",
    "            print(loss)\n",
    "            print('back')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "            # Track train loss\n",
    "            train_loss += loss.item()\n",
    "            train_acc = acc(x_train, y_train, network)\n",
    "\n",
    "        network.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_val_pred = network(x_val)\n",
    "            loss = criterion(y_val_pred, y_val)\n",
    "            val_loss = loss.item()\n",
    "            val_acc = acc(x_val, y_val, network)\n",
    "            loss_test = loss.item()\n",
    "\n",
    "            history_li.append([train_loss/BATCH_SIZE, val_loss, train_acc, val_acc])\n",
    "            torch.save(network.state_dict(), 'model_custom.pt')\n",
    "            torch.cuda.empty_cache()\n",
    "        print(\"Epoch {} | Train Loss {:.5f}, Train Acc {:.2f} - Test Loss {:.5f}, Test Acc {:.2f}\".format(\n",
    "            epoch, loss_train/BATCH_SIZE, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history = pd.DataFrame(history_li, columns=['train_loss', 'val_loss', 'train_acc', 'val_acc'])\n",
    "\n",
    "        loss_results['train'].append(loss_train/BATCH_SIZE)\n",
    "        loss_results['val'].append(val_loss)\n",
    "        \n",
    "        acc_results['train'].append(train_acc)\n",
    "        acc_results['val'].append(val_acc)\n",
    "\n",
    "#         for phase in ['train', 'val']:\n",
    "#             if phase == 'train':\n",
    "#                 network.train(True)\n",
    "#             else:\n",
    "#                 network.train(False)\n",
    "\n",
    "#             correct = 0\n",
    "#             number = 0\n",
    "\n",
    "#             for batch_idx, (data, target) in enumerate(loaders[phase]):\n",
    "#                 optimizer.zero_grad()\n",
    "#                 output = network(data)\n",
    "\n",
    "#                 loss = criterion(output, target)\n",
    "\n",
    "#                 if phase == 'train':\n",
    "#                     loss.backward()\n",
    "#                     optimizer.step()\n",
    "\n",
    "#                 total_loss[phase].append(loss.item())\n",
    "\n",
    "#                 _, predicted = torch.max(output.data, 1)\n",
    "#                 number += target.size(0)\n",
    "#                 correct += (predicted == target).sum().item()\n",
    "\n",
    "#             loss_results[phase].append(sum(total_loss[phase]) / len(total_loss[phase]))\n",
    "#             acc_results[phase].append(100 * correct / number)\n",
    "\n",
    "#         progress = 100.0 * (epoch + 1) / epochs\n",
    "\n",
    "#         print(f'Training [{int(progress)}%]\\tTraining loss {loss_results[\"train\"][-1]}\\tValidation loss {loss_results[\"val\"][-1]}\\tTraining acc {acc_results[\"train\"][-1]}\\tValidation acc {acc_results[\"val\"][-1]}')\n",
    "        \n",
    "    return {\n",
    "        'train_loss': loss_results[\"train\"][-1],\n",
    "        'val_loss': loss_results[\"val\"][-1],\n",
    "        'train_acc': acc_results[\"train\"][-1],\n",
    "        'val_acc': acc_results[\"val\"][-1]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "inside circuit\n",
      "tensor([-1.5015,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.5015006065368652\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([-0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-0.0\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([-0.6654,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-0.6654409766197205\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "inside circuit\n",
      "tensor([0.0873, 0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.08731631189584732\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "inside circuit\n",
      "tensor([-0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-0.0\n",
      "inside circuit\n",
      "tensor([2.3137, 0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "2.313659429550171\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([-1.7340,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-1.7340492010116577\n",
      "inside circuit\n",
      "tensor([-0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-0.0\n",
      "inside circuit\n",
      "tensor([0.4289, 0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.4288686513900757\n",
      "inside circuit\n",
      "tensor([-0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-0.0\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "inside circuit\n",
      "tensor([4.3881, 0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "4.3880791664123535\n",
      "inside circuit\n",
      "tensor([-0.9631,  0.0000], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "-0.9631222486495972\n",
      "inside circuit\n",
      "tensor([0., 0.], grad_fn=<SelectBackward>)\n",
      "i[0].tolist()\n",
      "0.0\n",
      "tensor([[0.7307, 0.5004],\n",
      "        [0.6208, 0.6241],\n",
      "        [0.7301, 0.5012],\n",
      "        [0.6205, 0.6244],\n",
      "        [0.7300, 0.5013],\n",
      "        [0.7295, 0.5020],\n",
      "        [0.6919, 0.5477],\n",
      "        [0.6264, 0.6186],\n",
      "        [0.7299, 0.5015],\n",
      "        [0.7299, 0.5015],\n",
      "        [0.6225, 0.6225],\n",
      "        [0.6094, 0.6354],\n",
      "        [0.6234, 0.6215],\n",
      "        [0.6236, 0.6213],\n",
      "        [0.6207, 0.6242],\n",
      "        [0.5342, 0.7032],\n",
      "        [0.7302, 0.5012],\n",
      "        [0.7295, 0.5020],\n",
      "        [0.6258, 0.6191],\n",
      "        [0.5727, 0.6698],\n",
      "        [0.6258, 0.6191],\n",
      "        [0.6223, 0.6226],\n",
      "        [0.7261, 0.5062],\n",
      "        [0.7125, 0.5231],\n",
      "        [0.6220, 0.6229]], grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0])\n",
      "tensor(0.6928, grad_fn=<NllLossBackward>)\n",
      "back\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function TorchCircuitBackward returned an invalid gradient at index 0 - got [2, 1] but expected shape compatible with [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a39e173f0cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-42f378284740>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, optimizer, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'back'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.2.8/libexec/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function TorchCircuitBackward returned an invalid gradient at index 0 - got [2, 1] but expected shape compatible with [2]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()\n",
    "\n",
    "dataset = ConcatDataset([X_train, X_test])\n",
    "\n",
    "k_folds = 5\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "results = {}\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "  \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=BATCH_SIZE, sampler=test_subsampler)\n",
    "\n",
    "    network = Net()\n",
    "    network.apply(reset_weights)\n",
    "    \n",
    "#     optimizer = optim.Adam(network.parameters(), lr=0.00002)\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr = LR, momentum = 0.9)\n",
    "    \n",
    "    result = train_network(network, optimizer, trainloader, testloader)\n",
    "    \n",
    "    results[fold] = result\n",
    "    \n",
    "    print(result)\n",
    "    print('--------------------------------')\n",
    "\n",
    "print('--------------------------------')\n",
    "print('FINAL RESULTS')\n",
    "print('--------------------------------')\n",
    "print(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 25\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# loss_results = {\n",
    "#     'train': [],\n",
    "#     'val': []\n",
    "# }\n",
    "\n",
    "# acc_results = {\n",
    "#     'train': [],\n",
    "#     'val': []\n",
    "# }\n",
    "\n",
    "# loaders = {\n",
    "#     'train': train_loader,\n",
    "#     'val': test_loader\n",
    "# }\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     total_loss = {\n",
    "#         'train': [],\n",
    "#         'val': []\n",
    "#     }\n",
    "    \n",
    "#     total_acc = {\n",
    "#         'train': [],\n",
    "#         'val': []\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     for phase in ['train', 'val']:\n",
    "#         if phase == 'train':\n",
    "#             network.train(True)\n",
    "#         else:\n",
    "#             network.train(False)\n",
    "        \n",
    "#         correct = 0\n",
    "#         number = 0\n",
    "        \n",
    "#         for batch_idx, (data, target) in enumerate(loaders[phase]):\n",
    "#             optimizer.zero_grad()\n",
    "#             output = network(data)\n",
    "            \n",
    "#             loss = loss_func(output, target)\n",
    "            \n",
    "#             if phase == 'train':\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#             total_loss[phase].append(loss.item())\n",
    "\n",
    "#             _, predicted = torch.max(output.data, 1)\n",
    "#             number += target.size(0)\n",
    "#             correct += (predicted == target).sum().item()\n",
    "\n",
    "#         loss_results[phase].append(sum(total_loss[phase]) / len(total_loss[phase]))\n",
    "#         acc_results[phase].append(100 * correct / number)\n",
    "\n",
    "#     progress = 100.0 * (epoch + 1) / epochs\n",
    "    \n",
    "#     print(f'Training [{int(progress)}%]\\tTraining loss {loss_results[\"train\"][-1]}\\tValidation loss {loss_results[\"val\"][-1]}\\tTraining acc {acc_results[\"train\"][-1]}\\tValidation acc {acc_results[\"val\"][-1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss_results[\"train\"])\n",
    "# plt.title(f'Hybrid NN training convergence for {NUM_QUBITS}-qubits')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss_results[\"val\"])\n",
    "# plt.title(f'Hybrid NN training convergence for {NUM_QUBITS}-qubits')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = 0\n",
    "# number = 0\n",
    "# for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#     number += 1\n",
    "#     output = network.predict(data).item()\n",
    "#     accuracy += (output == target[0].item())*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Performance on test data: {accuracy}/{number} = {accuracy/number*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sample_shape = (8, 6)\n",
    "# count = 0\n",
    "# fig, axes = plt.subplots(nrows=n_sample_shape[0], ncols=n_sample_shape[1], figsize=(10, 2*n_sample_shape[0]))\n",
    "\n",
    "# classes_map = {\n",
    "#     0: 'T-shirt/top',\n",
    "#     1: 'Trouser',\n",
    "#     2: 'Pullover',\n",
    "#     3: 'Dress',\n",
    "#     4: 'Coat',\n",
    "#     5: 'Sandal',\n",
    "#     6: 'Shirt',\n",
    "#     7: 'Sneaker',\n",
    "#     8: 'Bag',\n",
    "#     9: 'Ankle boot'\n",
    "# }\n",
    "\n",
    "# network.eval()\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#         if count == n_sample_shape[0]*n_sample_shape[1]:\n",
    "#             break\n",
    "        \n",
    "#         prediction = network.predict(data).item()\n",
    "        \n",
    "#         axes[count // n_sample_shape[1]][count % n_sample_shape[1]].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "        \n",
    "#         axes[count // n_sample_shape[1]][count % n_sample_shape[1]].set_xticks([])\n",
    "#         axes[count // n_sample_shape[1]][count % n_sample_shape[1]].set_yticks([])\n",
    "#         axes[count // n_sample_shape[1]][count % n_sample_shape[1]].set_title(classes_map[prediction])\n",
    "        \n",
    "#         count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
